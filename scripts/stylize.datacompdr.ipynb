{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!echo 'deb [trusted=yes] https://apt.fury.io/ascii-image-converter/ /' | tee /etc/apt/sources.list.d/ascii-image-converter.list"
      ],
      "metadata": {
        "id": "UibuLKzpBcv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt update\n",
        "!apt install -y ascii-image-converter"
      ],
      "metadata": {
        "id": "bllIXG1OBLsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKxVnXi47sjj"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets pyarrow requests scrapscii tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import io\n",
        "import itertools\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import datasets\n",
        "import pyarrow.lib as pl\n",
        "import pyarrow.parquet as pq\n",
        "import requests\n",
        "import tqdm\n",
        "\n",
        "import scrapscii.data\n",
        "import scrapscii.unicode"
      ],
      "metadata": {
        "id": "-qNm1jYv8NX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANTS ####################################################################\n",
        "\n",
        "WIDTH_MIN = 16\n",
        "WIDTH_MAX = 128\n",
        "SHARD_LEN = 2**10 # min size of a dataset shard\n",
        "TOTAL_LEN = 2**15"
      ],
      "metadata": {
        "id": "b6Jq5zmM8c2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IO ###########################################################################\n",
        "\n",
        "TEMP_PATH = tempfile.mkdtemp()\n",
        "DATA_PATH = '/content/dataset/'"
      ],
      "metadata": {
        "id": "yjzFksTz8iCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETUP ########################################################################\n",
        "\n",
        "os.makedirs(DATA_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "lAbMSr188vry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK ########################################################################\n",
        "\n",
        "CORRUPTED_HASH = ['4dcb57651a75abfd07fb36c70c6c5108c49bdb34']\n",
        "\n",
        "def is_valid_image(image: bytes) -> bool:\n",
        "    return (\n",
        "        bool(image)\n",
        "        and type(image) == bytes\n",
        "        and not hashlib.sha1(image).hexdigest() in CORRUPTED_HASH)\n",
        "\n",
        "def is_valid_ascii(ascii: str, width: int=WIDTH_MIN) -> bool:\n",
        "    return (\n",
        "        bool(ascii)\n",
        "        and type(ascii) == str\n",
        "        and len(ascii) >= width\n",
        "        and not 'error: can\\'t decode' in ascii.lower())"
      ],
      "metadata": {
        "id": "X1iE-sTF9cIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXTRACT ######################################################################\n",
        "\n",
        "# shard index\n",
        "__shard = 0\n",
        "\n",
        "# download the dataset\n",
        "__table = []\n",
        "__dataset = datasets.load_dataset('apple/DataCompDR-12M', split='train', streaming=True)\n",
        "__iter = itertools.islice(__dataset, 0, TOTAL_LEN)\n",
        "\n",
        "# iterate over the samples\n",
        "for __sample in tqdm.tqdm(__iter, total=TOTAL_LEN):\n",
        "\n",
        "    # parse the URL\n",
        "    __url = __sample['url.txt']\n",
        "    __hash = hashlib.sha1(__url.encode('utf-8')).hexdigest()\n",
        "    __path = urllib.parse.urlparse(__url).path\n",
        "    __filename = __path.split('/')[-1]\n",
        "    __extension = os.path.splitext(__filename)[-1]\n",
        "\n",
        "    # download image from URL\n",
        "    try:\n",
        "        __response = requests.get(__url, timeout=2)\n",
        "    except:\n",
        "        tqdm.tqdm.write(f'Failed to download {__url}')\n",
        "        continue\n",
        "\n",
        "    # save image on disk\n",
        "    __path = os.path.join(TEMP_PATH, __hash + __extension)\n",
        "    __bytes = __response.content\n",
        "    if is_valid_image(__bytes):\n",
        "        with open(__path, 'b+w') as __file:\n",
        "            __file.write(__bytes)\n",
        "    else:\n",
        "        tqdm.tqdm.write(f'Skip corrupted {__url}')\n",
        "        continue\n",
        "\n",
        "    # choose the config randomly\n",
        "    __width = '--width {width}'.format(width=random.randint(WIDTH_MIN, WIDTH_MAX))\n",
        "    __braille = '--braille' if random.choice([True, False]) else ''\n",
        "    __complex = '--complex' if random.choice([True, False]) else ''\n",
        "    __dither = '--dither' if __braille and random.choice([True, False]) else ''\n",
        "    __grayscale = '--grayscale' if random.choice([False]) else '' # colorless terminal\n",
        "    __negative = '--negative' if random.choice([True, False]) else ''\n",
        "\n",
        "    # choose a caption among the synthetic text\n",
        "    __index = random.randint(0, len(__sample['syn.json']['syn_text']) - 1)\n",
        "    __caption = __sample['syn.json']['syn_text'][__index]\n",
        "\n",
        "    # export the conversion config\n",
        "    __labels = [__l for __l in [__width, __braille, __complex, __dither, __grayscale, __negative] if __l]\n",
        "\n",
        "    # convert the image to ASCII art\n",
        "    __flags = list(itertools.chain.from_iterable(__l.split(' ') for __l in __labels if __l))\n",
        "    __process = subprocess.run(['ascii-image-converter'] + __flags + [__path], stdout=subprocess.PIPE)\n",
        "    __content = __process.stdout.decode('utf-8')\n",
        "\n",
        "    # check for conversion errors\n",
        "    if is_valid_ascii(__content):\n",
        "        __table.append({\n",
        "            'caption': __caption,\n",
        "            'content': __content,\n",
        "            'labels': ','.join(__labels),\n",
        "            'charsets': ','.join(set(scrapscii.unicode.lookup_section(__c) for __c in __content)),\n",
        "            'chartypes': ','.join(set(scrapscii.unicode.lookup_category(__c) for __c in __content)),})\n",
        "    else:\n",
        "        tqdm.tqdm.write(f'Failed to convert {__url}')\n",
        "        continue\n",
        "\n",
        "    # chunk the dataset into shards\n",
        "    if len(__table) >= SHARD_LEN:\n",
        "        # export as parquet\n",
        "        pq.write_table(\n",
        "            table=pl.Table.from_pylist(\n",
        "                mapping=__table,\n",
        "                schema=scrapscii.data.SCHEMA),\n",
        "            where=os.path.join(DATA_PATH, '{shard:0>4d}.parquet'.format(shard=__shard)))\n",
        "        # refresh\n",
        "        __shard += 1\n",
        "        __table = []\n",
        "\n",
        "# export the remainder\n",
        "if len(__table) > 0:\n",
        "    pq.write_table(\n",
        "        table=pl.Table.from_pylist(\n",
        "            mapping=__table,\n",
        "            schema=scrapscii.data.SCHEMA),\n",
        "        where=os.path.join(DATA_PATH, '{shard:0>4d}.parquet'.format(shard=__shard)))"
      ],
      "metadata": {
        "id": "p2BwDXnd9gb8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}